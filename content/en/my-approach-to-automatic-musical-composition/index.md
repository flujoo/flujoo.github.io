---
title: My Approach to Automatic Musical Composition
date: "2022-02-02"
tags:
    - music
comment: true
cn: false
---


In this blog, I will introduce my approach to automatic musical composition, including the theory, the algorithm, and a Python package implementation [ch0p1n](https://github.com/flujoo/ch0p1n).


## What Is Automatic Composition?

Automatic composition is using algorithms to generate music.

As a trivial example, imagine that you put a cat on a piano to randomly press keys to generate music. The music is thus the result of a predetermined algorithm rather than of your instantaneous emotions or compositional skills. This is why it is called *automatic* composition.

Automatic composition has many different approaches or paradigms.[^1] The approach I take is inspired by the theories of Arnold Schoenberg, Heinrich Schenker and William Caplin. The key idea is that **music can develop or be generated from limited materials under some common operations**. I will explain the theoretical foundation of my approach in the following three sections.


## Generate Music from Limited Materials

Let's see an example, the beginning of Beethoven's first piano sonata:

![](assets/beethoven_sonata.png)

<audio controls>
  <source src="assets/beethoven_sonata.mp3" type="audio/mpeg">
</audio>

As indicated below, the two framed structures are almost identical:

![](assets/beethoven_sonata_repeat_1.png)

In fact, the structure in the blue frame can be generated by merely transposing the structure in the red one. Therefore, to compose this piece, I need only to create the structure in the red frame, then reuse or slightly modify it to generate the structure in the blue frame, rather than create both structures from scratch.

The same situation happens in other parts too. As indicated below, the four framed structures are also highly similar:

![](assets/beethoven_sonata_repeat_2.png)

Does this kind of reuse exist only in Beethoven's music? No, this probably happens in every musical work. **No matter how long a musical work lasts or how varied it can sound, the amount of its core materials is always small.**

For another example, the following is an excerpt from Mozart's K. 485:

![](assets/mozart_rondo.png)

Sometimes, however, a material can be modified so much that you can barely recognize it, as in the following example, the beginning of Chopinâ€™s nocturne Op.9 No.1:

![](assets/chopin_op9_no1_repeat.png)

<audio controls>
  <source src="assets/chopin_op9_no1.mp3" type="audio/mpeg">
</audio>

The two framed structures look and sound quite different, but, in my approach, it is still that the structure in the blue frame can be generated by elaborating the structure in the red one, rather than that they are totally unrelated. It is so because the two structures have some morphological characteristics in common, they have the same background harmonic progression, and from the perspective of musical form, the structure in the blue frame is indeed a repetition of the structure in the red one.[^2]

Please note that, in stating that a structure can be generated from other structure, I do not assert that Beethoven or Chopin actually did this or deliberately did this when composing music. Rather, my point is that we can use this music generation perspective to formalize or automate the process of musical composition.


## Common Operations to Manipulate Materials

Once a structure is created, some common operations can be applied to them to generate new structures. I will talk about some operations below.

The first operation I will talk about is **repetition**. It means repeating a structure in a new harmony without changing its morphology.

The Beethoven's sonata is an example of repetition:

![](assets/beethoven_sonata_repeat_1.png)

The structure in the blue frame is a **transposition** of the structure in the red one. The two structures have the same morphology, although they are adapted to different background harmonies.

The Chopin's nocturne is another example. The accompaniment motif in the blue frame is a repetition of the one in the red frame:

![](assets/chopin_op9_no1_accompaniment.png)

In the repetition, some pitches move to their nearest pitches to fit the new harmony, according to some [voice-leading](https://en.wikipedia.org/wiki/Voice_leading) rules.[^3] Some of these changes are indicated below:

![](assets/chopin_op9_no1_accompaniment_2.png)

<audio controls>
  <source src="assets/chopin_op9_no1_accompaniment_2.mp3" type="audio/mpeg">
</audio>

The next operation is **elaboration**. It means adding passing notes, neighbor notes, and other types of notes to a structure. The Chopin's nocturne is an example, in which a lot of tuplets are added in the repetition:

![](assets/chopin_op9_no1_repeat.png)

Sometimes, elaborations are rather inferred from than showed in scores. Heinrich Schenker's theory differentiates music's superficial structure from its deep structure(s), and the superficial structure is the outcome of elaboration of a deep structure, as showed in the following example:[^4]

![](assets/elaboration.png)

In the above score, for example, piece b can be generated by elaborating piece c.

The opposite operation of elaboration is **reduction**. For example, in the above score, piece b can be reduced to piece c.

The last operation I will talk about is **fragmentation**. It means taking a fragment from a material.

As in the Beethoven's sonata, the structure in the blue frame is a fragment from the structure in the red one:

![](assets/beethoven_sonata_fragment.png)

The Chopin's nocturne is a more interesting example:

![](assets/chopin_op9_no1_antecedent_fragment.png)

<audio controls>
  <source src="assets/chopin_op9_no1_antecedent.mp3" type="audio/mpeg">
</audio>

The fragment in the red frame can be modified to generate the structure in the orange frame; the fragment in the blue frame can be modified to generate the structures in the green frames. The two fragments are taken from the structure in the purple frame.

There are more operations can be applied to musical materials, but I will stop here. The four operations I have introduced are enough for the purpose of this blog.


## Combine Materials According to Musical Forms

Created and generated structures can be combined into larger structures, according to musical forms. A **musical form** is a way in which musical materials should be organized.

For example, the beginning of the Beethoven's sonata has the form **sentence**. Below is how this sentence is analyzed in William Caplin's system:[^2]

![](assets/beethoven_sonata_caplin.png)

The beginning of the Chopin's nocturne is from a larger structure of the form **compound period**, which is far more complex than sentence.

I will not go deep into the subject of musical forms here. I highly recommend William Caplin's excellent textbook[^2] on this topic. My key point is that musical materials should be combined according to musical forms to generate meaningful music.


## Summary of the Theoretical Foundation

There are three key concepts in the theory behind my approach:

1. **limited core materials**, from which more materials can be generated,
2. **common operations**, which can be applied to materials to generate more, and
3. **musical forms**, according to which materials should be combined.

Now it is time to turn the theory into an algorithm.


## Represent Musical Structures

We first need to strictly define musical *materials* and *structures*, which we have been talking about quite vaguely.

Let's return to the Beethoven's sonata. Below is its first two bars:

![](assets/beethoven_sonata_basic_idea.png)

This piece of music has two voices or musical lines. Each musical line consists of notes, rests or chords which consist of notes too. A note has several attributes, among which only pitch and duration will be considered here. Rather than represent notes as single objects, we will handle their pitch and durational contents separately.

**Pitches** can be represented by [scientific pitch notations](https://en.wikipedia.org/wiki/Scientific_pitch_notation) or [MIDI note numbers](https://en.wikipedia.org/wiki/Scientific_pitch_notation#Table_of_note_frequencies). Mostly, the latter are used, for ease of operation. For example, pitch C4 is represented by MIDI note number 60.

The pitch content of a **rest** can be represented by `None` in Python.

The pitch contents of a **chord** can be represented by list in Python. For example, in Python we can use `['C4', 'A-3', 'F3']` or `[60, 56, 53]` to represent the pitch contents of the chord in the red frame:

![](assets/beethoven_sonata_chord.png)

**Durations** can be represented by numbers. For example, quarter note's duration is 1.

The pitch contents of a **musical line** can be represented by what I call **pitch line**. In Python, a pitch line is a list whose members are `None`, numbers or lists of numbers. With Python package [typing](https://docs.python.org/3/library/typing.html), pitch line can be defined as:

```python
from typing import List, Union

Pitch = int
PitchLine = List[Union[None, Pitch, List[Pitch]]]
```

The durational contents of a musical line can be represented by **duration line**. In Python, a duration line is a list whose members are numbers.

Finally, **harmonies** and **scales** can be represented by lists of [pitch classes](https://en.wikipedia.org/wiki/Pitch_class#Other_ways_to_label_pitch_classes). For example, in Python C major harmony can be represented by `['C', 'E', 'G']` or `[0, 4, 7]`.


## Motifs

You may have heard this term a lot. A **motif** is structurally a musical line, usually short in length. Motifs are the building blocks of music. They can be repeated, elaborated, fragmented and combined to generate music.

For example, the following is how Schoenberg analysed the beginning of the Beethoven's sonata:[^5]

![](assets/beethoven_sonata_schoenberg.png)

In his analysis, the melody part of this piece can be generated from only three motifs.

There are different kinds of motifs. For example, two kinds of motifs are framed in the following score:

![](assets/chopin_op9_no1_motifs.png)

The motifs in the red frames can be called **accompaniment motifs** as they appear in the accompaniment line of this nocturne. They can also be called **harmonic motifs** as they consist of only harmonic notes. The motifs in the blue frames can be called **melodic motifs** as they appear in the melody line, or **non-harmonic motifs** if they contain non-harmonic notes.

In the following several sections, I will talk about the implementation of the common operations that can be applied to motifs.


## Implementation of Repetition: `transpose()`

The function `transpose()` from my Python package [ch0p1n](https://github.com/flujoo/ch0p1n) is for transposing a motif along a scale.

Suppose there is a motif which can be represented as:

```python
pitch_motif = [60, 67, 76, 72]
# ['C4', 'G4', 'E5', 'C5']

duration_motif = [1, 1, 1, 1]
```

Remember that we separately represent a motif's pitch and durational contents.

We can show this motif in score with `show()`, which is built on Python package [music21](https://github.com/cuthbertLab/music21):

```python
from ch0p1n.utils import show

show(
  pitch_lines = [pitch_motif],
  duration_lines = [duration_motif],
  group = 1, # the number of voices in the treble staff
  key = 0,
  meter = '4/4',
  clefs = ['g', 'f']
)
```

![](assets/transpose_original.png)

Transpose it up by one step along the C major scale:

```python
from ch0p1n.motif import transpose

pitch_motif_transposed = transpose(
  pitch_motif = pitch_motif,
  scale = [0, 2, 4, 5, 7, 9, 11],
  step = 1
)
```

The code is pretty self-explanatory. Let's check the result:

```python
>>> pitch_motif_transposed

[62, 69, 77, 74]
```

```python
show(
  pitch_lines = [pitch_motif_transposed],
  duration_lines = [duration_motif],
  group = 1, # the number of voices in the treble staff
  key = 0,
  meter = '4/4',
  clefs = ['g', 'f']
)
```

![](assets/transpose_scale.png)

It looks good. Every pitch has moved up by one step along the C major scale.

Since harmony is a special kind of scale, we can use `transpose()` to repeat the motif in a harmony, say, the G major harmony:

```python
pitch_motif_transposed = transpose(
  pitch_motif = pitch_motif,
  scale = [7, 11, 2], # G major harmony
  step = 1
)
```

Let's show the original and transposed motifs together:

```python
show(
  pitch_lines = [pitch_motif + pitch_motif_transposed],
  duration_lines = [duration_motif * 2],
  group = 1,
  key = 0,
  meter = '4/4',
  clefs = ['g', 'f']
)
```

![](assets/transpose_harmony.png)

The original motif is in the first bar, and the transposed the second. You can see how each pitch moves up by one step in the G major harmony.

In some cases, however, `transpose()` does not work well. Still in the above example, suppose we transpose the motif down rather than up by one step with `step = -1`:

![](assets/transpose_fail.png)

The transposed motif in the second bar is not acceptable because it contains no pitch class G to fully reify the G major harmony.


## Implementation of Repetition: `lead()`

We can improve this situation with function `lead()` from [ch0p1n](https://github.com/flujoo/ch0p1n). The function got its name from the concept of voice-leading, which means every note in a motif *leads* by step to the note(s) in a given harmony.

Let's give it a try:

```python
from ch0p1n.motif import lead

pitch_motifs = lead(
  pitch_motif = pitch_motif,
  harmony = [7, 11, 2], # G major harmony
  steps = [-1, 0],
  complete = False,
  similar = None
)
```

`steps = [-1, 0]` means each pitch will move zero step if it fits the harmony, and at the same time one step downwards. In other words, each pitch may generate more than one pitch in the given harmony under `lead()`, and the result returned is thus a list of pitch motifs rather than a single one. I will talk about parameters `complete` and `similar` later.

Let's check the result:

```python
>>> pitch_motifs

[
  [59, 62, 74, 71],
  [59, 67, 74, 71]
]
```

There are two pitch motifs generated. Let's show them in score:

```python
# to merge `pitch_motifs`
from itertools import chain

show(
  pitch_lines = [list(chain(*pitch_motifs))],
  duration_lines = [duration_motif * 2],
  group = 1,
  key = 0,
  meter = '4/4',
  clefs = ['g', 'f']
)
```

![](assets/lead.png)

While the motif in the first bar is as same as the unacceptable one generated by `transpose()` with `step = -1`, the motif in the second bar is good, which fully reifies the G major harmony.

With `complete = True`, we can screen out the pitch motifs which are not harmonically complete or do not fully reify the given harmony:

```python
pitch_motifs = lead(
  pitch_motif = pitch_motif,
  harmony = [7, 11, 2],
  steps = [-1, 0],
  complete = True,
  similar = None
)
```

Now there leaves only one pitch motif, the good one:

```python
>>> pitch_motifs

[
  [59, 67, 74, 71]
]
```

With parameter `similar`, we can screen out the pitch motifs which do not have the same contour as the original one. I will skip this part in this introductory blog.


## Implementation of Repetition: `adapt()`

The function `adapt()` is for repeating a motif across harmonies. Let's try it on the motif defined earlier:

```python
from ch0p1n.motif import adapt

pitch_motifs = adapt(
  pitch_motif = pitch_motif,
  duration_motif = duration_motif,
  harmonies = [[5, 9, 0], [7, 11, 2]], # F, G
  durations = [2, 2],
  steps = [1]
)

show(
  pitch_lines = pitch_motifs,
  duration_lines = [duration_motif],
  group = 1,
  key = 0,
  meter = '2/4',
  clefs = ['g', 'f']
)
```

![](assets/adapt.png)

The first two notes of the motif are adapted to the F major harmony, while the last two notes to the G major harmony.

So far, I have talked only about harmonic motifs. To deal with non-harmonic motifs, which is more complex, we need first to consider how to elaborate and reduce motifs.


## Implementation of Elaboration and Reduction

Simply speaking, elaboration is adding notes to a motif. The function `elaborate()` from [ch0p1n](https://github.com/flujoo/ch0p1n) serves the exact purpose.



[^1]: Nierhaus, G. (2009). Algorithmic Composition: Paradigms of Automated Music Generation. Springer Science & Business Media.

[^2]: Caplin, William E. (2013). Analyzing Classical Form: an Approach for the Classroom. Oxford and New York: Oxford University Press.

[^3]: Huron, D. (2001). Tone and voice: A derivation of the rules of voice-leading from perceptual principles. Music Perception, 19(1), 1-64.

[^4]: Pankhurst, T. (2008). SchenkerGUIDE: a brief handbook and website for Schenkerian analysis (p. 11). Routledge.

[^5]: Schoenberg, A., Stein, L., & Strang, G. (1967). Fundamentals of musical composition (p. 63). London: Faber & Faber.
